{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdfe8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from time import time\n",
    "import dill \n",
    "import random as rd\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, RandomizedSearchCV\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179f8155",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('exoTrain.csv')\n",
    "test = pd.read_csv('exoTest.csv')\n",
    "\n",
    "train.iloc[:,0] = train.iloc[:,0]-1 #change labels to 0,1\n",
    "test.iloc[:,0] = test.iloc[:,0]-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31d3ca2",
   "metadata": {},
   "source": [
    "# Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ef99a5",
   "metadata": {},
   "source": [
    "## Basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e822723",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = train.iloc[:,1:].mean(axis=1)\n",
    "std = train.iloc[:,1:].std(axis=1)\n",
    "\n",
    "exo_mean = means[0:37]\n",
    "exo_sd = std[0:37]\n",
    "\n",
    "no_mean = means[37:]\n",
    "no_sd = std[37:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5140ee20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13,5))\n",
    "fig.suptitle('Mean fluxes for stars with and without confirmed exoplanets', fontsize=15)\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "ax.hist(exo_mean, bins=20)\n",
    "ax.set_ylabel('Number of stars')\n",
    "ax.set_xlabel('Mean flux (arbitrary units)')\n",
    "ax.set_title('Histogram of mean flux values for star with confirmed exoplanets')\n",
    "ax.grid()\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.hist(no_mean, bins=20)\n",
    "ax.set_ylabel('Number of stars')\n",
    "ax.set_xlabel('Mean flux (arbitrary units)')\n",
    "ax.set_title('Histogram of mean flux values for star with no confirmed exoplanets')\n",
    "ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bdf282",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(exo_mean[exo_mean>-800], bins=5) #Star number 27 might be an outlier\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25c5b6f",
   "metadata": {},
   "source": [
    "## Stars with exoplanet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db73a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_span = (75*24*60)/3197\n",
    "x = np.arange(3197) * (time_span/60.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae15241",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,20))\n",
    "fig.suptitle('Light curves of stars 1 to 20 with confirmed exoplanet in the training set', fontsize=20)\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "for i in range(20):\n",
    "    ax = fig.add_subplot(5,4,i+1)\n",
    "    ax.set_title('Star {}'.format(i+1))\n",
    "    ax.set_ylabel('Flux (arbitrary units)')\n",
    "    ax.set_xlabel('Time ($h$)')\n",
    "    ax.plot(x, train.iloc[i,1:])\n",
    "    ax.grid()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(15,20))\n",
    "fig.suptitle('Light curves of stars 21 to 37 with confirmed exoplanet in the training set', fontsize=20)\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "for i in range(20,37):\n",
    "    ax = fig.add_subplot(5,4,i-19)\n",
    "    ax.set_title('Star {}'.format(i+1))\n",
    "    ax.set_ylabel('Flux (arbitrary units)')\n",
    "    ax.set_xlabel('Time ($h$)')\n",
    "    ax.plot(x, train.iloc[i,1:])\n",
    "    ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a99a21b",
   "metadata": {},
   "source": [
    "### Closer view of some of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c62d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "fig.suptitle('Light curves of stars 8, 12, 13 and 37 with confirmed exoplanet', fontsize=20)\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "index = [7,11,12,30]\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(2,2,i+1)\n",
    "    ax.set_title('Star {}'.format(index[i]+1))\n",
    "    ax.set_ylabel('Flux (arbitrary units)')\n",
    "    ax.set_xlabel('Time ($h$)')\n",
    "    ax.plot(x, train.iloc[index[i],1:])\n",
    "    ax.grid()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print([means[i] for i in index])\n",
    "print([std[i] for i in index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4b8ab8",
   "metadata": {},
   "source": [
    "## Stars w/o exoplanet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8676a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,20))\n",
    "fig.suptitle('Light curves of 20 random stars without confirmed exoplanet in the training set', fontsize=20)\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "rd.seed(12345)\n",
    "index = rd.sample(range(37,5087), 20)\n",
    "for i in range(20):\n",
    "    ax = fig.add_subplot(5,4,i+1)\n",
    "    ax.set_title('Star {}'.format(index[i]+1))\n",
    "    ax.set_ylabel('Flux (arbitrary units)')\n",
    "    ax.set_xlabel('Time ($h$)')\n",
    "    ax.plot(x, train.iloc[index[i],1:])\n",
    "    ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a62641",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Star 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f42bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return (x-np.mean(x)) / np.std(x)\n",
    "\n",
    "def smoothing(x):\n",
    "    return sp.ndimage.filters.gaussian_filter(x, sigma=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9c099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed = smoothing(train.iloc[11,1:])\n",
    "detrended = train.iloc[11,1:]-smoothed\n",
    "stand = norm(detrended)\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "fig.suptitle('Pre-processing of Star 12 with confirmed exoplanet', fontsize=20)\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "ax = fig.add_subplot(221)\n",
    "ax.set_title('Original light curve')\n",
    "ax.set_ylabel('Flux (arbitrary units)')\n",
    "ax.set_xlabel('Time ($h$)')\n",
    "ax.plot(x, train.iloc[11,1:])\n",
    "ax.grid()\n",
    "\n",
    "ax = fig.add_subplot(222)\n",
    "ax.set_title('Smoothed light curve')\n",
    "ax.set_ylabel('Flux (arbitrary units)')\n",
    "ax.set_xlabel('Time ($h$)')\n",
    "ax.plot(x, smoothed)\n",
    "ax.grid()\n",
    "\n",
    "ax = fig.add_subplot(223)\n",
    "ax.set_title('Detrended light curve')\n",
    "ax.set_ylabel('Flux (arbitrary units)')\n",
    "ax.set_xlabel('Time ($h$)')\n",
    "ax.plot(x, detrended)\n",
    "ax.grid()\n",
    "\n",
    "ax = fig.add_subplot(224)\n",
    "ax.set_title('Standardized light curve')\n",
    "ax.set_ylabel('Flux (arbitrary units)')\n",
    "ax.set_xlabel('Time ($h$)')\n",
    "ax.plot(x, stand)\n",
    "ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b098f6",
   "metadata": {},
   "source": [
    "## Pre-processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a4f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(x):\n",
    "    smooth = sp.ndimage.filters.gaussian_filter(x, sigma=5)\n",
    "    detrend = x- smooth\n",
    "    scale = (detrend-np.mean(detrend)) / np.std(detrend)\n",
    "    return scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2503deaf",
   "metadata": {},
   "source": [
    "# Test models\n",
    "\n",
    "\n",
    "## Resampled, no pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249dbac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline\n",
    "over = RandomOverSampler()\n",
    "under = RandomUnderSampler()\n",
    "steps = [('o', over), ('u', under), ('knn', KNeighborsClassifier())]\n",
    "clf = Pipeline(steps=steps)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=1)\n",
    "\n",
    "param_grid={'o__sampling_strategy' : list(linspace(0.1,0.3,3)), 'u__sampling_strategy' : list(linspace(0.3,0.6,3)), 'knn__n_neighbors' : list(range(1,6,2))}\n",
    "\n",
    "clf = GridSearchCV(clf,\n",
    "param_grid,\n",
    "scoring='recall',\n",
    "cv=cv , n_jobs=-1, verbose=1)\n",
    "\n",
    "# evaluate pipeline\n",
    "np.random.seed(12345)\n",
    "clf=clf.fit(x_train,y_train)\n",
    "#predictions\n",
    "pred = clf.predict(x_test)\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, pred)\n",
    "plt.title(\"ROC - AUC\", fontsize=15)\n",
    "\n",
    "plt.show()\n",
    "RocCurveDisplay.from_estimator(clf, x_test, y_test)\n",
    "plt.title(\"ROC - AUC\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test,pred), annot = True, cmap = \"BuPu\", fmt = \"d\", linecolor = \"k\")\n",
    "plt.title(\"Confusion Matrix\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9986e8cb",
   "metadata": {},
   "source": [
    "## Resampled, Pre-processed with fft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170b41f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.iloc[:,1:] = train.iloc[:,1:].apply(norm, axis=1)\n",
    "test.iloc[:,1:] = test.iloc[:,1:].apply(norm, axis=1)\n",
    "\n",
    "x_train = train.drop([\"LABEL\"], axis=1)\n",
    "y_train = train[\"LABEL\"]   \n",
    "x_test = test.drop([\"LABEL\"], axis=1)\n",
    "y_test = test[\"LABEL\"]\n",
    "\n",
    "from numpy.fft import rfft\n",
    "x_fft =np.empty([5087,1599], dtype=complex)\n",
    "for i in range(x_train.shape[0]):\n",
    "    x_fft[i,:] = rfft(x_train.iloc[i,:])\n",
    "\n",
    "x_fft=abs(x_fft)\n",
    "\n",
    "x_fft_test =np.empty([570,1599])\n",
    "for i in range(x_test.shape[0]):\n",
    "    x_fft_test[i,:] = abs(rfft(x_test.iloc[i,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d3dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline\n",
    "over = RandomOverSampler()\n",
    "under = RandomUnderSampler()\n",
    "steps = [('o', over), ('u', under), ('knn', KNeighborsClassifier())]\n",
    "clf = Pipeline(steps=steps)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=1)\n",
    "\n",
    "param_grid={'o__sampling_strategy' : list(linspace(0.1,0.3,3)), 'u__sampling_strategy' : list(linspace(0.3,0.6,3)), 'knn__n_neighbors' : list(range(1,6,2))}\n",
    "\n",
    "clf = GridSearchCV(clf,\n",
    "param_grid,\n",
    "scoring='recall',\n",
    "cv=cv , n_jobs=-1, verbose=1)\n",
    "\n",
    "# evaluate pipeline\n",
    "np.random.seed(12345)\n",
    "clf=clf.fit(x_fft,y_train)\n",
    "#predictions\n",
    "pred = clf.predict(x_fft_test)\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, pred)\n",
    "plt.title(\"ROC - AUC\", fontsize=15)\n",
    "\n",
    "plt.show()\n",
    "RocCurveDisplay.from_estimator(clf, x_fft_test, y_test)\n",
    "plt.title(\"ROC - AUC\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test,pred), annot = True, cmap = \"BuPu\", fmt = \"d\", linecolor = \"k\")\n",
    "plt.title(\"Confusion Matrix\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf8793f",
   "metadata": {},
   "source": [
    "## Pre-processed, no resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d312083",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('exoTrain.csv')\n",
    "test = pd.read_csv('exoTest.csv')\n",
    "\n",
    "train.iloc[:,0] = train.iloc[:,0]-1 #change labels to 0,1\n",
    "test.iloc[:,0] = test.iloc[:,0]-1\n",
    "\n",
    "train.iloc[:,1:] = train.iloc[:,1:].apply(preprocessing, axis=1)\n",
    "test.iloc[:,1:] = test.iloc[:,1:].apply(preprocessing, axis=1)\n",
    "\n",
    "x_train = train.drop([\"LABEL\"], axis=1)\n",
    "y_train = train[\"LABEL\"]   \n",
    "x_test = test.drop([\"LABEL\"], axis=1)\n",
    "y_test = test[\"LABEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c21bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=1)\n",
    "\n",
    "param_grid={'n_neighbors' : list(range(1,6,2))}\n",
    "\n",
    "clf = GridSearchCV(clf,\n",
    "param_grid,\n",
    "scoring='roc_auc',\n",
    "cv=cv , n_jobs=-1, verbose=1)\n",
    "\n",
    "# evaluate pipeline\n",
    "np.random.seed(12345)\n",
    "clf=clf.fit(x_train,y_train)\n",
    "#predictions\n",
    "pred = clf.predict(x_test)\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, pred)\n",
    "plt.title(\"ROC - AUC\", fontsize=15)\n",
    "\n",
    "plt.show()\n",
    "RocCurveDisplay.from_estimator(clf, x_test, y_test)\n",
    "plt.title(\"ROC - AUC\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test,pred), annot = True, cmap = \"BuPu\", fmt = \"d\", linecolor = \"k\")\n",
    "plt.title(\"Confusion Matrix\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82883ac9",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff4c720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluator(over, model, param_grid, refit, n_iter=25):\n",
    "    t=time()\n",
    "\n",
    "    steps = [('over', over), ('under', RandomUnderSampler()), ('model', model)]\n",
    "    clf = Pipeline(steps=steps)\n",
    "\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    clf = RandomizedSearchCV(clf, param_grid, scoring=['roc_auc', 'recall', 'f1'], cv=cv , n_jobs=-1, verbose=1, refit=refit, n_iter=n_iter)\n",
    "    \n",
    "    np.random.seed(12345)\n",
    "    clf=clf.fit(x_train,y_train)\n",
    "    total=time()-t\n",
    "    \n",
    "    print('\\n')\n",
    "    print('Resampling with {}'.format(str(over)+' for a model: '+str(model)+' and ' + str(refit)+' as the metric to refit.'),\n",
    "          '\\n\\n') \n",
    "    print('It took {0:.4g} seconds to tune and train the model. \\n\\n'.format(total))\n",
    "    \n",
    "    best_params = clf.best_params_\n",
    "    print('Best Parameters: \\n', best_params, '\\n\\n')\n",
    "    \n",
    "    pred = clf.predict(x_test)\n",
    "    c_matrix = confusion_matrix(y_test,pred)\n",
    "    clf_report = classification_report(y_test,pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', c_matrix, '\\n')\n",
    "    print('Classification report: \\n', clf_report, '\\n')\n",
    "    \n",
    "    sns.heatmap(c_matrix, annot = True, cmap = \"BuPu\", fmt = \"d\", linecolor = \"k\")\n",
    "    plt.title(\"Confusion Matrix\", fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "    RocCurveDisplay.from_predictions(y_test, pred)\n",
    "    plt.title(\"ROC - AUC\", fontsize=15)\n",
    "    plt.show()\n",
    "    \n",
    "    RocCurveDisplay.from_estimator(clf, x_test, y_test)\n",
    "    plt.title(\"ROC - AUC\", fontsize=15)\n",
    "    plt.show()\n",
    "    \n",
    "    columns = ['mean_fit_time','mean_test_recall', 'rank_test_recall', 'mean_test_f1', \n",
    "               'rank_test_f1','mean_test_roc_auc','rank_test_roc_auc']\n",
    "    params=list()\n",
    "    for key in param_grid:\n",
    "        params.append('_'.join(['param', key]))\n",
    "    cols = columns + params\n",
    "    sort_by='_'.join(['rank_test',refit])\n",
    "    cv_res = pd.DataFrame(clf.cv_results_).sort_values(by=sort_by).reset_index().loc[:,cols]\n",
    "    \n",
    "    print('Evaluation metrics: \\n')\n",
    "    print(cv_res.head(), '\\n ------------------------------------------------------- \\n\\n')\n",
    "    \n",
    "    return clf, pred, total, best_params, c_matrix, clf_report, cv_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f8d6e1",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "* Gaussian Naive Bayes\n",
    "* K-Nearest Neighbors\n",
    "* Support Vector Machine:\n",
    "    * SVMLinear\n",
    "    * SVM rbf (Radial basis function)\n",
    "    * SVM Poly (degree: 2- 4)\n",
    "* Decision trees\n",
    "* Ensemble methods:\n",
    "    * Random Forest\n",
    "    * Gradient Boosting\n",
    "    * AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe7912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dual=False porque n_samples>n_features en SVCLinear ---- , LinearSVC(dual=False)\n",
    "models =[GaussianNB(), KNeighborsClassifier(), SVC(kernel='linear'), SVC(kernel='poly'), SVC(kernel='rbf'), DecisionTreeClassifier(), RandomForestClassifier(), \n",
    "         GradientBoostingClassifier(), AdaBoostClassifier()]\n",
    "\n",
    "grid_GNB = {'over__sampling_strategy' : list(np.linspace(0.1,0.5,5)), 'under__sampling_strategy' : list(np.linspace(0.5,0.9,5))}\n",
    "\n",
    "grid_KNN = {'over__sampling_strategy' : list(np.linspace(0.1,0.5,5)), 'under__sampling_strategy' : list(np.linspace(0.5,0.9,5)),\n",
    "            'model__n_neighbors' : list(range(1,8,2))} \n",
    "\n",
    "grid_SVCL = {'over__sampling_strategy' : list(np.linspace(0.1,0.5,5)), 'under__sampling_strategy' : list(np.linspace(0.5,0.9,5)),\n",
    "             'model__C' : [0.1,1,5,10,100,1000]}\n",
    "\n",
    "grid_SVCP = {'over__sampling_strategy' : list(np.linspace(0.1,0.5,5)), 'under__sampling_strategy' : list(np.linspace(0.5,0.9,5)),\n",
    "            'model__C' : [0.1,1,5,10,100,1000], 'model__degree' : [2,3,4]}\n",
    "\n",
    "grid_SVCR = {'over__sampling_strategy' : list(np.linspace(0.1,0.5,5)), 'under__sampling_strategy' : list(np.linspace(0.5,0.9,5)),\n",
    "            'model__C' : [0.1,1,5,10,100,1000]}\n",
    "\n",
    "#grid_SVL = {'over__sampling_strategy' : list(np.linspace(0.1,0.5,5)), 'under__sampling_strategy' : list(np.linspace(0.5,0.9,5)),\n",
    "           # 'model__C' : list(np.linspace(1,2,4))}\n",
    "\n",
    "grid_tree = {'over__sampling_strategy' : list(np.linspace(0.1,0.5,5)), 'under__sampling_strategy' : list(np.linspace(0.5,0.9,5)),\n",
    "            'model__criterion' : ['gini', 'entropy'], 'model__max_depth' : list(range(6,31,2))}\n",
    "\n",
    "grid_RF = {'over__sampling_strategy' : list(np.linspace(0.1,0.5,5)), 'under__sampling_strategy' : list(np.linspace(0.5,0.9,5)),\n",
    "           'model__criterion' : ['gini', 'entropy'], 'model__n_estimators' : list(range(50,201,50)),\n",
    "           'model__max_depth' : list(range(6,31,2)), 'model__max_features' : ['sqrt', 'log2']}\n",
    "\n",
    "grid_GB = {'over__sampling_strategy' : list(np.linspace(0.1,0.5,5)), 'under__sampling_strategy' : list(np.linspace(0.5,0.9,5)),\n",
    "            'model__n_estimators' : list(range(50,201,50)), 'model__max_depth' : list(range(2,21,2)), \n",
    "            'model__learning_rate' : [0.01,0.1,0.2,0.3,0.5]}\n",
    "\n",
    "grid_ada = {'over__sampling_strategy' : list(np.linspace(0.1,0.5,5)), 'under__sampling_strategy' : list(np.linspace(0.5,0.9,5)),\n",
    "            'model__n_estimators' : list(range(50,151,50)),'model__learning_rate' : [0.01,0.1,0.2,0.3,0.5]}\n",
    "\n",
    "param_grids = [grid_GNB, grid_KNN, grid_SVCL, grid_SVCP, grid_SVCR, grid_tree, grid_RF, grid_GB, grid_ada]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8018e31",
   "metadata": {},
   "source": [
    "## Evaluation time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df22a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "over = list()\n",
    "smote = list()\n",
    "\n",
    "time0 = time()\n",
    "\n",
    "for i in range(len(models)):\n",
    "    over.append(evaluator(RandomOverSampler(), models[i], param_grids[i], refit='roc_auc'))\n",
    "    smote.append(evaluator(SMOTE(), models[i], param_grids[i], refit='roc_auc')  )\n",
    "    filepath = '_'.join(['session', str(i), str(models[i]),'.pkl'])\n",
    "    dill.dump_session(filepath) # Save the session in each iteration\n",
    "    \n",
    "    \n",
    "time1 = time() - time0\n",
    "print('Total time consumed by all the models: {}'.format(time1), 'seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757ba3dc",
   "metadata": {},
   "source": [
    "# Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f2f6f2",
   "metadata": {},
   "source": [
    "## Finding best tuned parameters according to other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda0b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_params(res, model, param_grid):\n",
    "    n = len(param_grid)\n",
    "    f1 = res[6].iloc[:,[0,2,4,6] +list(range(len(res[6].columns)-n,len(res[6].columns)))].sort_values(by='rank_test_f1').reset_index()\n",
    "    recall = res[6].iloc[:,[0,2,4,6] +list(range(len(res[6].columns)-n,len(res[6].columns)))].sort_values(by='rank_test_recall').reset_index()\n",
    "    \n",
    "    f1_bp= dict(f1.iloc[0,list(range(len(f1.columns)-n,len(f1.columns)))])\n",
    "    recall_bp= dict(recall.iloc[0,list(range(len(recall.columns)-n,len(recall.columns)))])\n",
    "    return f1, recall, f1_bp, recall_bp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35d1e70",
   "metadata": {},
   "source": [
    "This will evaluate other hyper parameter combinations if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0b3032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_2(steps):   \n",
    "    clf = Pipeline(steps=steps)\n",
    "    \n",
    "    np.random.seed(12345)\n",
    "    clf=clf.fit(x_train,y_train)\n",
    "    \n",
    "    pred = clf.predict(x_test)\n",
    "    c_matrix = confusion_matrix(y_test,pred)\n",
    "    clf_report = classification_report(y_test,pred)\n",
    "    \n",
    "    print('Confusion Matrix: \\n', c_matrix, '\\n')\n",
    "    print('Classification report: \\n', clf_report, '\\n')\n",
    "    \n",
    "    sns.heatmap(c_matrix, annot = True, cmap = \"BuPu\", fmt = \"d\", linecolor = \"k\")\n",
    "    plt.title(\"Confusion Matrix\", fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "    RocCurveDisplay.from_predictions(y_test, pred)\n",
    "    plt.title(\"ROC - AUC\", fontsize=15)\n",
    "    plt.show()\n",
    "    \n",
    "    RocCurveDisplay.from_estimator(clf, x_test, y_test)\n",
    "    plt.title(\"ROC - AUC\", fontsize=15)\n",
    "    plt.show()\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e846b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    print('OVERSAMPLING + '+str(models[i]) + '\\n')\n",
    "    f1, recall, f1_bp, recall_bp = best_params(over[i], models[i], param_grids[i])\n",
    "    print('F1 \\n', f1_bp, '\\n')\n",
    "    print('Recall \\n', recall_bp, '\\n')\n",
    "    \n",
    "    print('SMOTE + '+str(models[i]) + '\\n')\n",
    "    f1, recall, f1_bp, recall_bp = best_params(smote[i], models[i], param_grids[i])\n",
    "    print('F1 \\n', f1_bp, '\\n')\n",
    "    print('Recall \\n', recall_bp, '\\n')\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc2d3cd",
   "metadata": {},
   "source": [
    "Let´s see if we can improve KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f0e79a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "over=0.5\n",
    "under=0.7\n",
    "model=KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "steps = [('over', RandomOverSampler(sampling_strategy=over)), ('under', RandomUnderSampler(sampling_strategy=under)), ('model', model)]\n",
    "\n",
    "o = evaluator_2(steps)\n",
    "\n",
    "steps = [('over', SMOTE(sampling_strategy=over)), ('under', RandomUnderSampler(sampling_strategy=under)), ('model', model)]\n",
    "\n",
    "s=evaluator_2(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d665c0bc",
   "metadata": {},
   "source": [
    "This is the **best model** so far: \n",
    "* over=0.5\n",
    "* under=0.7\n",
    "* model=KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "with RandomOverSampler.\n",
    "\n",
    "Let´s try the rest of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32f4eb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "over=0.5\n",
    "under=0.5\n",
    "model=GaussianNB()\n",
    "\n",
    "steps = [('over', RandomOverSampler(sampling_strategy=over)), ('under', RandomUnderSampler(sampling_strategy=under)), ('model', model)]\n",
    "\n",
    "o = evaluator_2(steps)\n",
    "\n",
    "steps = [('over', SMOTE(sampling_strategy=over)), ('under', RandomUnderSampler(sampling_strategy=under)), ('model', model)]\n",
    "\n",
    "s=evaluator_2(steps)\n",
    "\n",
    "\n",
    "###########################################\n",
    "\n",
    "model =SVC(kernel='linear', C=100)\n",
    "over=0.1\n",
    "under=0.9\n",
    "\n",
    "steps = [('over', RandomOverSampler(sampling_strategy=over)), ('under', RandomUnderSampler(sampling_strategy=under)), ('model', model)]\n",
    "\n",
    "o = evaluator_2(steps)\n",
    "\n",
    "model =SVC(kernel='linear', C=1000)\n",
    "over=0.2\n",
    "under=0.9\n",
    "\n",
    "steps = [('over', SMOTE(sampling_strategy=over)), ('under', RandomUnderSampler(sampling_strategy=under)), ('model', model)]\n",
    "\n",
    "s=evaluator_2(steps)\n",
    "\n",
    "###########################################\n",
    "\n",
    "model =SVC(kernel='poly', C=1000, degree=2)\n",
    "over=0.1\n",
    "under=0.9\n",
    "\n",
    "steps = [('over', RandomOverSampler(sampling_strategy=over)), ('under', RandomUnderSampler(sampling_strategy=under)), ('model', model)]\n",
    "\n",
    "o = evaluator_2(steps)\n",
    "\n",
    "\n",
    "#############################################\n",
    "\n",
    "model =SVC(kernel='rbf', C=1000)\n",
    "over=0.1\n",
    "under=0.8\n",
    "\n",
    "steps = [('over', SMOTE(sampling_strategy=over)), ('under', RandomUnderSampler(sampling_strategy=under)), ('model', model)]\n",
    "\n",
    "s=evaluator_2(steps)\n",
    "\n",
    "###############################################\n",
    "\n",
    "model =DecisionTreeClassifier(criterion='gini', max_depth=28)\n",
    "over=0.2\n",
    "under=.6\n",
    "\n",
    "steps = [('over', RandomOverSampler(sampling_strategy=over)), ('under', RandomUnderSampler(sampling_strategy=under)), ('model', model)]\n",
    "\n",
    "o = evaluator_2(steps)\n",
    "\n",
    "model =DecisionTreeClassifier(criterion='gini', max_depth=22)\n",
    "over=0.5\n",
    "under=0.5\n",
    "\n",
    "steps = [('over', SMOTE(sampling_strategy=over)), ('under', RandomUnderSampler(sampling_strategy=under)), ('model', model)]\n",
    "\n",
    "s=evaluator_2(steps)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "model =RandomForestClassifier(criterion='entropy', n_estimators=100, max_depth=14,max_features='sqrt')\n",
    "over=0.1\n",
    "under=0.9\n",
    "\n",
    "steps = [('over', RandomOverSampler(sampling_strategy=over)), ('under', RandomUnderSampler(sampling_strategy=under)), ('model', model)]\n",
    "\n",
    "o = evaluator_2(steps)\n",
    "\n",
    "############################################################\n",
    "\n",
    "model =GradientBoostingClassifier(n_estimators=200, max_depth=2, learning_rate=0.5)\n",
    "over=0.4\n",
    "under=0.9\n",
    "\n",
    "steps = [('over', RandomOverSampler(sampling_strategy=over)), ('under', RandomUnderSampler(sampling_strategy=under)), ('model', model)]\n",
    "\n",
    "o = evaluator_2(steps)\n",
    "\n",
    "model =GradientBoostingClassifier(n_estimators=150, max_depth=2, learning_rate=0.1)\n",
    "over=0.1\n",
    "under=0.8\n",
    "\n",
    "steps = [('over', SMOTE(sampling_strategy=over)), ('under', RandomUnderSampler(sampling_strategy=under)), ('model', model)]\n",
    "\n",
    "s=evaluator_2(steps)\n",
    "\n",
    "#######################################################\n",
    "\n",
    "model =AdaBoostClassifier(n_estimators=150, learning_rate=0.5)\n",
    "over=0.3\n",
    "under=0.8\n",
    "\n",
    "steps = [('over', RandomOverSampler(sampling_strategy=over)), ('under', RandomUnderSampler(sampling_strategy=under)), ('model', model)]\n",
    "\n",
    "o = evaluator_2(steps)\n",
    "\n",
    "model =AdaBoostClassifier(n_estimators=100, learning_rate=0.5)\n",
    "over=0.5\n",
    "under=0.5\n",
    "\n",
    "steps = [('over', SMOTE(sampling_strategy=over)), ('under', RandomUnderSampler(sampling_strategy=under)), ('model', model)]\n",
    "\n",
    "s=evaluator_2(steps)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
